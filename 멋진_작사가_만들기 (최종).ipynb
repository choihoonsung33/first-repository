{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "멋진 작사가 만들기",
      "provenance": [],
      "collapsed_sections": [
        "5L-NH2i_OeWl",
        "dGfgE3esOsui"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 6-4. 실습 (1) 데이터 다듬기"
      ],
      "metadata": {
        "id": "5L-NH2i_OeWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "# 파일을 읽기모드로 열고\n",
        "# 라인 단위로 끊어서 list 형태로 읽어옵니다.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/aiffel/lyricist/data/shakespeare.txt'\n",
        "with open(file_path, \"r\") as f:\n",
        "    raw_corpus = f.read().splitlines()\n",
        "\n",
        "# 앞에서부터 10라인만 화면에 출력해 볼까요?\n",
        "print(raw_corpus[:9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiDhQB0MOins",
        "outputId": "27b37a14-ee00-4855-b500-0b41a47a8590"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['First Citizen:', 'Before we proceed any further, hear me speak.', '', 'All:', 'Speak, speak.', '', 'First Citizen:', 'You are all resolved rather to die than to famish?', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sentence in enumerate(raw_corpus):\n",
        "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
        "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
        "\n",
        "    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
        "        \n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaww7X47MQb5",
        "outputId": "11534404-b1f3-444f-b7e3-1e1123aa0aa1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before we proceed any further, hear me speak.\n",
            "Speak, speak.\n",
            "You are all resolved rather to die than to famish?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력된 문장을\n",
        "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
        "#     2. 특수문자 양쪽에 공백을 넣고\n",
        "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
        "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
        "#     5. 다시 양쪽 공백을 지웁니다\n",
        "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
        "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 1\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
        "    sentence = sentence.strip() # 5\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
        "    return sentence\n",
        "\n",
        "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHe5RYdrNclX",
        "outputId": "c2ca765c-ddf2-4539-a1a1-699d671d150b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 여기에 정제된 문장을 모을겁니다\n",
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    # 정제를 하고 담아주세요\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "# 정제된 결과를 10개만 확인해보죠\n",
        "corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phhqQ-44NmSY",
        "outputId": "e1a94de9-f9c0-474d-c9fb-fa9cee5a2e4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> before we proceed any further , hear me speak . <end>',\n",
              " '<start> speak , speak . <end>',\n",
              " '<start> you are all resolved rather to die than to famish ? <end>',\n",
              " '<start> resolved . resolved . <end>',\n",
              " '<start> first , you know caius marcius is chief enemy to the people . <end>',\n",
              " '<start> we know t , we know t . <end>',\n",
              " '<start> let us kill him , and we ll have corn at our own price . <end>',\n",
              " '<start> is t a verdict ? <end>',\n",
              " '<start> no more talking on t let it be done away , away ! <end>',\n",
              " '<start> one word , good citizens . <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
        "# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
        "def tokenize(corpus):\n",
        "    # 7000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
        "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
        "    # 7000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=7000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
        "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
        "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY6MGC-0N52O",
        "outputId": "f80b7597-d072-4d8e-94e2-7135cc1e8282"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2  143   40 ...    0    0    0]\n",
            " [   2  110    4 ...    0    0    0]\n",
            " [   2   11   50 ...    0    0    0]\n",
            " ...\n",
            " [   2  149 4553 ...    0    0    0]\n",
            " [   2   34   71 ...    0    0    0]\n",
            " [   2  945   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f83fc0ea950>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[:3, :10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQBUUO_OODEO",
        "outputId": "7043b9e4-7701-4133-f9db-779d515f8e6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2  143   40  933  140  591    4  124   24  110]\n",
            " [   2  110    4  110    5    3    0    0    0    0]\n",
            " [   2   11   50   43 1201  316    9  201   74    9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZVu10qdOITv",
        "outputId": "c5d75400-7c8b-4851-eb73-f611bc0586d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : .\n",
            "6 : the\n",
            "7 : and\n",
            "8 : i\n",
            "9 : to\n",
            "10 : of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
        "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
        "src_input = tensor[:, :-1]  \n",
        "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIf6ZYGUOL8c",
        "outputId": "93ab136d-6671-4609-fcf8-3a2e0d7d2b7f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2 143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0\n",
            "   0   0]\n",
            "[143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0   0\n",
            "   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
        "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
        "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q6s2JCAOPgm",
        "outputId": "0af1c2ca-874e-404d-9094-1207b234d80a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 20), dtype=tf.int32, name=None), TensorSpec(shape=(256, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-5. 실습 (2) 인공지능 학습시키기"
      ],
      "metadata": {
        "id": "dGfgE3esOsui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 256\n",
        "hidden_size = 1024\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "2dUld0XyPAsv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
        "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
        "model(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi8d-fanPLfe",
        "outputId": "97358274-8252-4de7-918e-26210f168021"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 20, 7001), dtype=float32, numpy=\n",
              "array([[[-1.9697910e-04,  2.5575518e-04,  3.5115832e-04, ...,\n",
              "          1.8613836e-04,  1.1259153e-04, -3.4533219e-05],\n",
              "        [-2.1533310e-04,  2.8350501e-04,  6.9371768e-04, ...,\n",
              "          3.3618600e-04,  4.9604551e-04, -1.6401125e-05],\n",
              "        [-2.6111875e-04,  3.8149286e-04,  9.0915384e-04, ...,\n",
              "          4.4032582e-04,  2.8339005e-04,  2.6473310e-04],\n",
              "        ...,\n",
              "        [-2.7635214e-03,  6.9706803e-03,  2.9073004e-03, ...,\n",
              "          1.5362573e-03, -2.0373582e-04,  1.6753789e-04],\n",
              "        [-2.7654383e-03,  7.5432253e-03,  3.0638871e-03, ...,\n",
              "          1.6098974e-03, -7.6594668e-05,  2.2722603e-04],\n",
              "        [-2.7457541e-03,  8.0586467e-03,  3.2077259e-03, ...,\n",
              "          1.6730599e-03,  3.3304910e-05,  2.9389068e-04]],\n",
              "\n",
              "       [[-1.9697910e-04,  2.5575518e-04,  3.5115832e-04, ...,\n",
              "          1.8613836e-04,  1.1259153e-04, -3.4533219e-05],\n",
              "        [-3.9050827e-04,  2.8913206e-04,  4.6891932e-04, ...,\n",
              "          2.9404738e-04, -3.5105156e-06, -8.8435636e-06],\n",
              "        [-8.0534542e-04,  2.5844033e-04,  4.9206987e-04, ...,\n",
              "          7.1974689e-05,  2.8778546e-04, -1.1168252e-04],\n",
              "        ...,\n",
              "        [-2.2927627e-03,  3.8030129e-03,  1.1828197e-03, ...,\n",
              "          7.2222011e-04, -5.8577053e-04,  1.4078573e-04],\n",
              "        [-2.4645098e-03,  4.6762642e-03,  1.6112931e-03, ...,\n",
              "          8.2862086e-04, -4.3612576e-04,  1.5623817e-04],\n",
              "        [-2.5810311e-03,  5.4940274e-03,  1.9987014e-03, ...,\n",
              "          9.3130994e-04, -2.9496427e-04,  1.9061899e-04]],\n",
              "\n",
              "       [[-1.9697910e-04,  2.5575518e-04,  3.5115832e-04, ...,\n",
              "          1.8613836e-04,  1.1259153e-04, -3.4533219e-05],\n",
              "        [-5.0975406e-04,  4.3569188e-04,  8.3039695e-04, ...,\n",
              "          4.4293853e-04,  1.8718991e-04,  1.7132601e-04],\n",
              "        [-5.7406421e-04,  6.0900807e-04,  1.1769773e-03, ...,\n",
              "          5.5666553e-04,  1.6270542e-04, -1.4100192e-04],\n",
              "        ...,\n",
              "        [-3.1077189e-03,  5.0772890e-03,  1.8398390e-03, ...,\n",
              "          1.9347164e-03,  5.5882116e-05, -9.4619347e-04],\n",
              "        [-3.1130568e-03,  5.8277650e-03,  2.1413353e-03, ...,\n",
              "          1.9150673e-03,  1.2790244e-04, -8.4230868e-04],\n",
              "        [-3.0909774e-03,  6.5218802e-03,  2.4186543e-03, ...,\n",
              "          1.9030292e-03,  1.9056883e-04, -7.1246276e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.9697910e-04,  2.5575518e-04,  3.5115832e-04, ...,\n",
              "          1.8613836e-04,  1.1259153e-04, -3.4533219e-05],\n",
              "        [-6.0928305e-05,  2.6327785e-04,  5.8360683e-04, ...,\n",
              "          4.1316953e-04, -9.8157878e-05, -1.2028944e-05],\n",
              "        [-3.0070858e-04,  3.1456523e-04,  6.1518973e-04, ...,\n",
              "          2.2116698e-04,  1.9468018e-04, -1.0416190e-04],\n",
              "        ...,\n",
              "        [-1.4450443e-03,  3.6858446e-03,  1.6287345e-03, ...,\n",
              "          1.6537417e-03,  5.4133881e-05,  2.2828185e-04],\n",
              "        [-1.7478778e-03,  4.4371523e-03,  1.9449274e-03, ...,\n",
              "          1.8011525e-03,  6.5264729e-05,  2.7680289e-04],\n",
              "        [-1.9917188e-03,  5.1611750e-03,  2.2420269e-03, ...,\n",
              "          1.9078796e-03,  9.2076007e-05,  3.3166545e-04]],\n",
              "\n",
              "       [[-1.9697910e-04,  2.5575518e-04,  3.5115832e-04, ...,\n",
              "          1.8613836e-04,  1.1259153e-04, -3.4533219e-05],\n",
              "        [ 8.3147977e-05,  4.1776983e-04,  4.7870298e-04, ...,\n",
              "          3.8578687e-04,  4.2402404e-04, -1.1358737e-04],\n",
              "        [ 3.5461457e-04,  7.1568851e-04,  5.0779595e-04, ...,\n",
              "          5.8810500e-04,  5.9001165e-04,  1.8389287e-04],\n",
              "        ...,\n",
              "        [-1.1231119e-03,  1.5613280e-03,  1.3984818e-04, ...,\n",
              "          1.3524810e-03, -6.7024352e-04,  1.6653846e-04],\n",
              "        [-1.4850677e-03,  2.4671759e-03,  5.9397798e-04, ...,\n",
              "          1.3424158e-03, -5.2715780e-04,  6.6896813e-05],\n",
              "        [-1.7806655e-03,  3.3686124e-03,  1.0361953e-03, ...,\n",
              "          1.3505635e-03, -3.9637316e-04,  2.3216246e-05]],\n",
              "\n",
              "       [[-1.9697910e-04,  2.5575518e-04,  3.5115832e-04, ...,\n",
              "          1.8613836e-04,  1.1259153e-04, -3.4533219e-05],\n",
              "        [-8.7328249e-04,  4.6401465e-04,  7.1670971e-04, ...,\n",
              "         -1.6118020e-04,  6.2566301e-05, -1.2505711e-04],\n",
              "        [-1.2098321e-03,  4.4050819e-04,  5.2731391e-04, ...,\n",
              "         -6.9091038e-04, -1.8369913e-04,  3.1703294e-04],\n",
              "        ...,\n",
              "        [-2.7454034e-03,  3.8630650e-03,  1.5321481e-03, ...,\n",
              "          3.3848031e-04, -8.6280968e-05,  8.9158898e-04],\n",
              "        [-2.8344418e-03,  4.6847924e-03,  1.8691808e-03, ...,\n",
              "          5.4199802e-04, -4.3763928e-05,  8.4445148e-04],\n",
              "        [-2.8873754e-03,  5.4578613e-03,  2.1796322e-03, ...,\n",
              "          7.2905701e-04,  7.3542374e-06,  8.0549141e-04]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTDN0La7PMBA",
        "outputId": "5329d611-d299-447c-90cc-b9ff1dc5531f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  1792256   \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  7176025   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,607,961\n",
            "Trainable params: 22,607,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer와 loss등은 차차 배웁니다 \n",
        "# 혹시 미리 알고 싶다면 아래 문서를 참고하세요\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "# 양이 상당히 많은 편이니 지금 보는 것은 추천하지 않습니다\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# model.fit() 함수에 들어가는 다양한 인자를 알고 싶다면 아래의 문서를 참고하세요. \n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
        "\n",
        "model.fit(dataset, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "OkN1v8EuPTbX",
        "outputId": "5ef2b7d8-b7fd-4ffd-d630-d5a272f30adb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "93/93 [==============================] - 12s 103ms/step - loss: 3.4610\n",
            "Epoch 2/30\n",
            "93/93 [==============================] - 10s 103ms/step - loss: 2.7937\n",
            "Epoch 3/30\n",
            "93/93 [==============================] - 10s 103ms/step - loss: 2.6816\n",
            "Epoch 4/30\n",
            "93/93 [==============================] - 10s 103ms/step - loss: 2.5875\n",
            "Epoch 5/30\n",
            "93/93 [==============================] - 10s 103ms/step - loss: 2.5281\n",
            "Epoch 6/30\n",
            "70/93 [=====================>........] - ETA: 2s - loss: 2.4699"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-732561b014a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-7. 프로젝트: 멋진 작사가 만들기"
      ],
      "metadata": {
        "id": "XAIzTU4hRsXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os, re \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "# 파일을 읽기모드로 열고\n",
        "# 라인 단위로 끊어서 list 형태로 읽어옵니다.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/aiffel/lyricist/data/lyrics/*'\n",
        "txt_list = glob.glob(file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgcmXASeSkKI",
        "outputId": "4442cd66-3f4c-48ab-ff34-9408c8b147a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "데이터 크기: 187088\n",
            "Examples:\n",
            " [\"Let's stay together I, I'm I'm so in love with you\", 'Whatever you want to do', 'Is all right with me']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sentence in enumerate(raw_corpus):\n",
        "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
        "\n",
        "    if idx > 9: break   # 문장 10개 확인\n",
        "        \n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaxedLskf7Zp",
        "outputId": "957a921f-4184-4148-de7f-87535a5b797d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's stay together I, I'm I'm so in love with you\n",
            "Whatever you want to do\n",
            "Is all right with me\n",
            "Cause you make me feel so brand new\n",
            "And I want to spend my life with you Let me say that since, baby, since we've been together\n",
            "Loving you forever\n",
            "Is what I need\n",
            "Let me, be the one you come running to\n",
            "I'll never be untrue Oh baby\n",
            "Let's, let's stay together (gether)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰화\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 특수문자 양쪽에 공백을 넣고\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개의 공백은 하나의 공백으로 바꿉니다\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
        "    sentence = sentence.strip() # 다시 양쪽 공백을 지웁니다\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "nRRolig3f7-t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#정제 데이터 구축하기\n",
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    if len(sentence) == 0: continue #길이 0\n",
        "    if len(sentence.split()) >= 13: continue  #15개 이하(start,end포함)\n",
        "    \n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "    \n",
        "    \n",
        "corpus[:10] #정제결과 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7QSnwKWgA3L",
        "outputId": "096bfc53-448a-45b5-df92-0190678899a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> let s stay together i , i m i m so in love with you <end>',\n",
              " '<start> whatever you want to do <end>',\n",
              " '<start> is all right with me <end>',\n",
              " '<start> cause you make me feel so brand new <end>',\n",
              " '<start> loving you forever <end>',\n",
              " '<start> is what i need <end>',\n",
              " '<start> let me , be the one you come running to <end>',\n",
              " '<start> i ll never be untrue oh baby <end>',\n",
              " '<start> let s , let s stay together gether <end>',\n",
              " '<start> lovin you whether , whether <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize() 함수로 데이터를 Tensor로 변환\n",
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000, #단어장의 크기:12,000 이상 \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    \n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)  # corpus를 Tensor로 변환 \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qc6-5qqgNP1",
        "outputId": "c66378d6-5d93-40c9-9db9-ee3dd198db43"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2  64  16 ...   0   0   0]\n",
            " [  2 576   7 ...   0   0   0]\n",
            " [  2  26  25 ...   0   0   0]\n",
            " ...\n",
            " [  2  42 904 ...   0   0   0]\n",
            " [  2  42  67 ...   0   0   0]\n",
            " [  2   8  83 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f82aff9da90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어사전 구축 인덱스 확인\n",
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break\n",
        "\n",
        "#생성된 텐서를 소스와 타겟으로 분리해 모델 학습\n",
        "src_input = tensor[:, :-1]   #소스 문장을 생성\n",
        "tgt_input = tensor[:, 1:]   #타겟 문장을 생성\n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZKCsj_egRkc",
        "outputId": "0131122b-7419-49f3-a24a-2694f8d09d29"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n",
            "[  2  64  16 215 277   5   4   5  23   5  23  31  14  37  30   7   3   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "[ 64  16 215 277   5   4   5  23   5  23  31  14  37  30   7   3   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 객체 생성\n",
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MScmfWcwgV9O",
        "outputId": "2f0b5438-d2c7-49e7-c8bd-a325afc365fb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 32), dtype=tf.int32, name=None), TensorSpec(shape=(256, 32), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_0lBoQOzc6M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#총 데이터의 20% 를 평가 데이터셋\n",
        "from sklearn.model_selection import train_test_split\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2)"
      ],
      "metadata": {
        "id": "qK9DG4EKgY8z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlnPUYGmc8du",
        "outputId": "f7d9aa20-d522-4fc3-f46e-5172363da170"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127100, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2YI5Qc1dONh",
        "outputId": "5d5d42be-57c6-41e6-d129-14ec9095fdfe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127100, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 256  # 워드 벡터의 차원수, 즉 단어가 추상적으로 표현되는 크기\n",
        "hidden_size = 1024  #모델에 얼마나 많은 일꾼을 둘 것인가\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "3y9OcfRNgcxL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러오기\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUinAEf2hKCI",
        "outputId": "e5adc31a-d75d-4562-dbfb-bcd1ffe45d15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 32, 12001), dtype=float32, numpy=\n",
              "array([[[ 1.2905369e-04, -4.6051946e-04,  1.5081636e-04, ...,\n",
              "          1.4101599e-04,  1.3058504e-05, -7.2385861e-05],\n",
              "        [ 2.0605205e-04, -9.7505096e-04,  2.3316887e-04, ...,\n",
              "          3.1202257e-04,  2.9182751e-04, -4.4447670e-04],\n",
              "        [ 2.2592454e-04, -1.4872287e-03,  2.7402752e-04, ...,\n",
              "          5.0595886e-04,  6.8606983e-04, -9.5890084e-04],\n",
              "        ...,\n",
              "        [-4.6140529e-04, -1.3787589e-04, -4.7785777e-04, ...,\n",
              "         -4.6344236e-03,  5.3898239e-04,  3.1513225e-03],\n",
              "        [-4.5685857e-04, -1.1829572e-04, -4.9138023e-04, ...,\n",
              "         -4.6474207e-03,  5.1479711e-04,  3.2146764e-03],\n",
              "        [-4.5256535e-04, -1.0250652e-04, -5.0339615e-04, ...,\n",
              "         -4.6565263e-03,  4.9075380e-04,  3.2693848e-03]],\n",
              "\n",
              "       [[ 1.2905369e-04, -4.6051946e-04,  1.5081636e-04, ...,\n",
              "          1.4101599e-04,  1.3058504e-05, -7.2385861e-05],\n",
              "        [ 2.1202574e-04, -7.6431117e-04,  9.9779943e-05, ...,\n",
              "         -7.8295634e-05,  3.0787272e-04, -1.8708612e-04],\n",
              "        [ 2.4954765e-04, -1.0132911e-03,  1.4635258e-04, ...,\n",
              "         -2.3355796e-04,  3.2698558e-04, -4.8793433e-04],\n",
              "        ...,\n",
              "        [-3.4726446e-04, -9.2396440e-05, -4.7335110e-04, ...,\n",
              "         -4.5560705e-03,  4.0986584e-04,  3.4206065e-03],\n",
              "        [-3.5332228e-04, -7.8774661e-05, -4.9076014e-04, ...,\n",
              "         -4.5792600e-03,  4.0337502e-04,  3.4485892e-03],\n",
              "        [-3.5874036e-04, -6.7566805e-05, -5.0586381e-04, ...,\n",
              "         -4.5978767e-03,  3.9422963e-04,  3.4721273e-03]],\n",
              "\n",
              "       [[ 1.2905369e-04, -4.6051946e-04,  1.5081636e-04, ...,\n",
              "          1.4101599e-04,  1.3058504e-05, -7.2385861e-05],\n",
              "        [-4.6614955e-06, -8.8795286e-04,  1.8657593e-04, ...,\n",
              "          4.0383352e-04,  6.7481313e-05, -1.7634175e-04],\n",
              "        [-1.6057651e-04, -1.0235441e-03,  2.2607639e-04, ...,\n",
              "          7.6898042e-04,  7.4756914e-05, -2.8338580e-04],\n",
              "        ...,\n",
              "        [-3.6429940e-04, -1.6466707e-04, -4.8131650e-04, ...,\n",
              "         -4.3777842e-03,  4.3428587e-04,  3.2970144e-03],\n",
              "        [-3.7230857e-04, -1.3604663e-04, -4.9849146e-04, ...,\n",
              "         -4.4258223e-03,  4.2879384e-04,  3.3429863e-03],\n",
              "        [-3.7910638e-04, -1.1239604e-04, -5.1340513e-04, ...,\n",
              "         -4.4666580e-03,  4.2037148e-04,  3.3818919e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.2905369e-04, -4.6051946e-04,  1.5081636e-04, ...,\n",
              "          1.4101599e-04,  1.3058504e-05, -7.2385861e-05],\n",
              "        [ 1.5038519e-07, -8.5175893e-04,  2.5715210e-04, ...,\n",
              "          2.6851869e-04, -2.4745244e-05, -1.7404060e-05],\n",
              "        [ 7.5470001e-05, -8.8012259e-04, -1.0092173e-04, ...,\n",
              "          2.1278892e-04, -3.2477611e-04, -1.7433552e-04],\n",
              "        ...,\n",
              "        [-1.5758887e-04, -3.5748020e-04, -4.0812863e-04, ...,\n",
              "         -4.2364760e-03,  4.0887090e-04,  3.0747526e-03],\n",
              "        [-1.9336837e-04, -3.0204514e-04, -4.2185589e-04, ...,\n",
              "         -4.2968593e-03,  4.2057238e-04,  3.1487697e-03],\n",
              "        [-2.2562763e-04, -2.5423849e-04, -4.3801795e-04, ...,\n",
              "         -4.3490524e-03,  4.2663512e-04,  3.2118307e-03]],\n",
              "\n",
              "       [[ 1.2905369e-04, -4.6051946e-04,  1.5081636e-04, ...,\n",
              "          1.4101599e-04,  1.3058504e-05, -7.2385861e-05],\n",
              "        [ 2.6220590e-04, -6.1842141e-04,  2.8854480e-04, ...,\n",
              "          1.9554177e-04,  1.4522127e-05,  1.1274934e-04],\n",
              "        [ 4.9936312e-04, -5.5675063e-04,  5.6685106e-04, ...,\n",
              "          4.0202194e-05,  2.7515991e-05,  3.5417548e-04],\n",
              "        ...,\n",
              "        [-3.9475388e-04, -1.1917419e-04, -5.3252728e-04, ...,\n",
              "         -4.5613782e-03,  3.8114333e-04,  3.4013598e-03],\n",
              "        [-3.9687863e-04, -1.0373394e-04, -5.4224324e-04, ...,\n",
              "         -4.5809373e-03,  3.7469520e-04,  3.4285798e-03],\n",
              "        [-3.9818606e-04, -9.0719113e-05, -5.5002840e-04, ...,\n",
              "         -4.5965933e-03,  3.6644517e-04,  3.4522773e-03]],\n",
              "\n",
              "       [[ 1.2905369e-04, -4.6051946e-04,  1.5081636e-04, ...,\n",
              "          1.4101599e-04,  1.3058504e-05, -7.2385861e-05],\n",
              "        [-1.3474823e-05, -8.6370436e-04,  2.7621074e-05, ...,\n",
              "          2.4440911e-04, -2.2351842e-04, -1.1435871e-04],\n",
              "        [-4.2529812e-04, -1.0897910e-03,  3.2526274e-05, ...,\n",
              "          5.9759559e-04, -4.3903873e-04, -3.8181443e-04],\n",
              "        ...,\n",
              "        [-3.6684208e-04, -8.9987901e-05, -4.9939821e-04, ...,\n",
              "         -4.6448447e-03,  4.0062593e-04,  3.4299134e-03],\n",
              "        [-3.7288846e-04, -7.8920828e-05, -5.1175844e-04, ...,\n",
              "         -4.6496540e-03,  3.8712760e-04,  3.4558889e-03],\n",
              "        [-3.7767016e-04, -6.9622969e-05, -5.2215852e-04, ...,\n",
              "         -4.6525896e-03,  3.7359993e-04,  3.4782477e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg0ekKqXhNG3",
        "outputId": "3c187b66-7ae5-4a42-9781-8e3388b9fe84"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     multiple                  3072256   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  12301025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,012,961\n",
            "Trainable params: 29,012,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습하기\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, \n",
        "          dec_train, \n",
        "          epochs=10,\n",
        "          batch_size=256,\n",
        "          validation_data=(enc_val, dec_val),\n",
        "          verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUxLMerJhT4C",
        "outputId": "43114395-a544-46c3-e96b-c800838d94fc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "497/497 [==============================] - 112s 221ms/step - loss: 1.2135 - val_loss: 1.2281\n",
            "Epoch 2/10\n",
            "497/497 [==============================] - 109s 220ms/step - loss: 1.1451 - val_loss: 1.1990\n",
            "Epoch 3/10\n",
            "497/497 [==============================] - 107s 216ms/step - loss: 1.0921 - val_loss: 1.1768\n",
            "Epoch 4/10\n",
            "497/497 [==============================] - 109s 220ms/step - loss: 1.0431 - val_loss: 1.1597\n",
            "Epoch 5/10\n",
            "497/497 [==============================] - 109s 220ms/step - loss: 0.9979 - val_loss: 1.1462\n",
            "Epoch 6/10\n",
            "497/497 [==============================] - 109s 219ms/step - loss: 0.9557 - val_loss: 1.1354\n",
            "Epoch 7/10\n",
            "497/497 [==============================] - 109s 220ms/step - loss: 0.9168 - val_loss: 1.1268\n",
            "Epoch 8/10\n",
            "497/497 [==============================] - 108s 217ms/step - loss: 0.8805 - val_loss: 1.1192\n",
            "Epoch 9/10\n",
            "497/497 [==============================] - 109s 219ms/step - loss: 0.8466 - val_loss: 1.1148\n",
            "Epoch 10/10\n",
            "497/497 [==============================] - 109s 220ms/step - loss: 0.8159 - val_loss: 1.1099\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f82af1ecf10>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    # 단어 하나씩 예측해 문장을 만듭니다\n",
        "    while True:\n",
        "        # 입력받은 문장의 텐서를 입력\n",
        "        predict = model(test_tensor) \n",
        "        # 예측된 값 중 가장 높은 확률인 word index를 뽑기\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 예측된 word index를 문장 뒤에 붙임\n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마침\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "GAITyoM2hXnB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#문장 생성 함수 실행\n",
        "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "APJCIZwEHCwf",
        "outputId": "770e2b29-3494-42f6-e321-1043fcbbb8c0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love you <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[참조](https://github.com/yenaryu/AI/blob/main/%5BE-04%5Dlyricist_ai.ipynb)"
      ],
      "metadata": {
        "id": "ZbjaPmKlh_0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x10pcGQUHLt9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}