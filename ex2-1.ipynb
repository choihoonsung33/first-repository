{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**프로젝트 1 : 손수 설계하는 선형회귀, 당뇨병 수치를 맞춰보자!**","metadata":{}},{"cell_type":"markdown","source":"(1) 데이터 가져오기","metadata":{}},{"cell_type":"code","source":"from sklearn import datasets\ndataset = datasets.load_diabetes()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T05:56:05.139901Z","iopub.execute_input":"2022-07-22T05:56:05.140459Z","iopub.status.idle":"2022-07-22T05:56:05.810524Z","shell.execute_reply.started":"2022-07-22T05:56:05.140336Z","shell.execute_reply":"2022-07-22T05:56:05.809310Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"x_data = dataset.data\ny_data = dataset.target\nprint(x_data) \nprint(y_data)","metadata":{"id":"r0EQ_ViXtm8r","outputId":"e594e240-fc8a-450e-f174-2d254ad98ba0","execution":{"iopub.status.busy":"2022-07-22T05:56:05.812851Z","iopub.execute_input":"2022-07-22T05:56:05.813527Z","iopub.status.idle":"2022-07-22T05:56:05.827636Z","shell.execute_reply.started":"2022-07-22T05:56:05.813467Z","shell.execute_reply":"2022-07-22T05:56:05.826344Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"(2) 모델에 입력할 데이터 x, y 준비하기","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nx = np.array(x_data)\ny = np.array(y_data)\n","metadata":{"id":"y6GoBFO4w00m","execution":{"iopub.status.busy":"2022-07-22T05:56:05.828940Z","iopub.execute_input":"2022-07-22T05:56:05.829226Z","iopub.status.idle":"2022-07-22T05:56:05.842709Z","shell.execute_reply.started":"2022-07-22T05:56:05.829200Z","shell.execute_reply":"2022-07-22T05:56:05.841820Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"(3) train 데이터와 test 데이터로 분리하기","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"id":"1d4hN-bm3Y55","execution":{"iopub.status.busy":"2022-07-22T05:56:05.844853Z","iopub.execute_input":"2022-07-22T05:56:05.845562Z","iopub.status.idle":"2022-07-22T05:56:05.915336Z","shell.execute_reply.started":"2022-07-22T05:56:05.845519Z","shell.execute_reply":"2022-07-22T05:56:05.914108Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7)\nprint('X_train 개수:', len(X_train),',X_test 개수:', len(X_test))","metadata":{"id":"6cXssnG64KsE","outputId":"6d637b16-014a-41af-ec9b-c1dfbd663cb3","execution":{"iopub.status.busy":"2022-07-22T05:56:05.917392Z","iopub.execute_input":"2022-07-22T05:56:05.918208Z","iopub.status.idle":"2022-07-22T05:56:05.927769Z","shell.execute_reply.started":"2022-07-22T05:56:05.918163Z","shell.execute_reply":"2022-07-22T05:56:05.926588Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","metadata":{"id":"LF6Xex0N4Z-q","outputId":"f6405290-6028-48c9-b1ac-f3676ca90c73","execution":{"iopub.status.busy":"2022-07-22T05:56:05.930661Z","iopub.execute_input":"2022-07-22T05:56:05.931087Z","iopub.status.idle":"2022-07-22T05:56:05.938402Z","shell.execute_reply.started":"2022-07-22T05:56:05.931044Z","shell.execute_reply":"2022-07-22T05:56:05.937137Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"(4) 모델 준비하기","metadata":{}},{"cell_type":"code","source":"import numpy as np\nW = np.random.rand(10)\nb = np.random.rand()\nprint(\"GOOD\")","metadata":{"id":"jzBxYiz158ne","outputId":"9241da33-49c5-40b1-cdc8-d83acde45338","execution":{"iopub.status.busy":"2022-07-22T05:56:06.013365Z","iopub.execute_input":"2022-07-22T05:56:06.014621Z","iopub.status.idle":"2022-07-22T05:56:06.022017Z","shell.execute_reply.started":"2022-07-22T05:56:06.014567Z","shell.execute_reply":"2022-07-22T05:56:06.020721Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"W","metadata":{"id":"z61Wzy-a6O2H","outputId":"22ae9325-119e-4ffd-9930-91d7f2eb3ae4","execution":{"iopub.status.busy":"2022-07-22T05:56:06.118388Z","iopub.execute_input":"2022-07-22T05:56:06.119672Z","iopub.status.idle":"2022-07-22T05:56:06.130446Z","shell.execute_reply.started":"2022-07-22T05:56:06.119618Z","shell.execute_reply":"2022-07-22T05:56:06.129380Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"b","metadata":{"id":"ru2r5Zjm6TFs","outputId":"f87d9e19-e2a3-4959-8958-0e3a4d1bf872","execution":{"iopub.status.busy":"2022-07-22T05:56:06.223639Z","iopub.execute_input":"2022-07-22T05:56:06.224483Z","iopub.status.idle":"2022-07-22T05:56:06.231102Z","shell.execute_reply.started":"2022-07-22T05:56:06.224444Z","shell.execute_reply":"2022-07-22T05:56:06.230042Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def model(x, W, b):\n    predictions = 0\n    for i in range(10):\n        predictions += x[:, i] * W[i]\n    predictions += b\n    return predictions\nprint(\"GOOD\")","metadata":{"id":"UzJ1uDGJ6YRb","outputId":"4b373ff7-773c-4a1e-ee82-ca2bd984c39e","execution":{"iopub.status.busy":"2022-07-22T05:56:06.326172Z","iopub.execute_input":"2022-07-22T05:56:06.326912Z","iopub.status.idle":"2022-07-22T05:56:06.335921Z","shell.execute_reply.started":"2022-07-22T05:56:06.326870Z","shell.execute_reply":"2022-07-22T05:56:06.334759Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"(6) 손실함수 loss 정의하기","metadata":{}},{"cell_type":"code","source":"def MSE(a, b):\n    mse = ((a - b) ** 2).mean()  # 두 값의 차이의 제곱의 평균\n    return mse\nprint(\"GOOD\")","metadata":{"id":"ZRK5bIH96ioG","outputId":"b9104c85-b9e5-4582-d492-fc634b67c451","execution":{"iopub.status.busy":"2022-07-22T05:56:06.428342Z","iopub.execute_input":"2022-07-22T05:56:06.429625Z","iopub.status.idle":"2022-07-22T05:56:06.435967Z","shell.execute_reply.started":"2022-07-22T05:56:06.429578Z","shell.execute_reply":"2022-07-22T05:56:06.434998Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def loss(x, W, b, y):\n    predictions = model(x, W, b)\n    L = MSE(predictions, y)\n    return L\nprint(\"GOOD\")","metadata":{"id":"VbC9WymU6shl","outputId":"167b12e6-0834-4e9e-a161-41bab1ce238b","execution":{"iopub.status.busy":"2022-07-22T05:56:06.533069Z","iopub.execute_input":"2022-07-22T05:56:06.533941Z","iopub.status.idle":"2022-07-22T05:56:06.540879Z","shell.execute_reply.started":"2022-07-22T05:56:06.533885Z","shell.execute_reply":"2022-07-22T05:56:06.539813Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"(7) 기울기를 구하는 gradient 함수 구현하기","metadata":{}},{"cell_type":"code","source":"def gradient(x, W, b, y):\n    # N은 가중치의 개수\n    N = len(W)\n    \n    # y_pred 준비\n    y_pred = model(x, W, b)\n    \n    # 공식에 맞게 gradient 계산\n    dW = 1/N * 2 * x.T.dot(y_pred - y)\n        \n    # b의 gradient 계산\n    db = 2 * (y_pred - y).mean()\n    return dW, db\nprint(\"GOOD\")","metadata":{"id":"_uYlBDzj6yRp","outputId":"ede9dfc2-d22e-4cbf-c4fb-854804c3a3bb","execution":{"iopub.status.busy":"2022-07-22T05:56:06.634159Z","iopub.execute_input":"2022-07-22T05:56:06.635461Z","iopub.status.idle":"2022-07-22T05:56:06.642928Z","shell.execute_reply.started":"2022-07-22T05:56:06.635343Z","shell.execute_reply":"2022-07-22T05:56:06.641749Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dW, db = gradient(x, W, b, y)\nprint(\"dW:\", dW)\nprint(\"db:\", db)","metadata":{"id":"WBYQjX2E67rH","outputId":"88c10546-d864-4ee7-d102-3c861d9e4c1a","execution":{"iopub.status.busy":"2022-07-22T05:56:06.742310Z","iopub.execute_input":"2022-07-22T05:56:06.743114Z","iopub.status.idle":"2022-07-22T05:56:06.751111Z","shell.execute_reply.started":"2022-07-22T05:56:06.743067Z","shell.execute_reply":"2022-07-22T05:56:06.749813Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"(8) 하이퍼 파라미터인 학습률 설정하기","metadata":{}},{"cell_type":"code","source":"LEARNING_RATE = 0.1","metadata":{"id":"x10uhIJ87AHo","execution":{"iopub.status.busy":"2022-07-22T05:56:06.833433Z","iopub.execute_input":"2022-07-22T05:56:06.833804Z","iopub.status.idle":"2022-07-22T05:56:06.838490Z","shell.execute_reply.started":"2022-07-22T05:56:06.833775Z","shell.execute_reply":"2022-07-22T05:56:06.837578Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"(9) 모델 학습하기","metadata":{}},{"cell_type":"code","source":"losses = []\n\nfor i in range(1, 1001):\n    dW, db = gradient(X_train, W, b, y_train)\n    W -= LEARNING_RATE * dW\n    b -= LEARNING_RATE * db\n    L = loss(X_train, W, b, y_train)\n    losses.append(L)\n    if i % 10 == 0:\n        print('Iteration %d : Loss %0.4f' % (i, L))","metadata":{"id":"M8L4NvbP8Ruo","outputId":"a76a734b-aa9d-4d3e-94ed-57263cb096de","execution":{"iopub.status.busy":"2022-07-22T05:56:07.005013Z","iopub.execute_input":"2022-07-22T05:56:07.005499Z","iopub.status.idle":"2022-07-22T05:56:07.212076Z","shell.execute_reply.started":"2022-07-22T05:56:07.005451Z","shell.execute_reply":"2022-07-22T05:56:07.209185Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(losses)\nplt.show()","metadata":{"id":"o2hgi98C8WN9","outputId":"3e86164c-c429-43c8-f2a1-57864368ea63","execution":{"iopub.status.busy":"2022-07-22T05:56:07.213825Z","iopub.execute_input":"2022-07-22T05:56:07.214202Z","iopub.status.idle":"2022-07-22T05:56:07.432424Z","shell.execute_reply.started":"2022-07-22T05:56:07.214171Z","shell.execute_reply":"2022-07-22T05:56:07.431078Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"W, b","metadata":{"id":"Xy1OU92A8uID","outputId":"42fab385-dec5-45b4-b310-d4fb2ef070a1","execution":{"iopub.status.busy":"2022-07-22T05:56:07.435292Z","iopub.execute_input":"2022-07-22T05:56:07.435769Z","iopub.status.idle":"2022-07-22T05:56:07.444094Z","shell.execute_reply.started":"2022-07-22T05:56:07.435723Z","shell.execute_reply":"2022-07-22T05:56:07.442877Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"(10) test 데이터에 대한 성능 확인하기","metadata":{}},{"cell_type":"code","source":"prediction = model(X_test, W, b)\nmse = loss(X_test, W, b, y_test)\nmse","metadata":{"id":"AMjSov8U8_fT","outputId":"32aad46d-9c68-414d-fb5a-4ca6b3073877","execution":{"iopub.status.busy":"2022-07-22T05:56:07.446095Z","iopub.execute_input":"2022-07-22T05:56:07.446904Z","iopub.status.idle":"2022-07-22T05:56:07.458982Z","shell.execute_reply.started":"2022-07-22T05:56:07.446856Z","shell.execute_reply":"2022-07-22T05:56:07.457909Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"(11) 정답 데이터와 예측한 데이터 시각화하기","metadata":{}},{"cell_type":"code","source":"plt.scatter(X_test[:, 0], y_test)\nplt.scatter(X_test[:, 0], prediction)\nplt.show()","metadata":{"id":"jEk1AMmF9f-A","outputId":"1ef575a7-ed6e-4b06-d163-ea5067500a9c","execution":{"iopub.status.busy":"2022-07-22T05:56:07.472617Z","iopub.execute_input":"2022-07-22T05:56:07.472976Z","iopub.status.idle":"2022-07-22T05:56:07.681691Z","shell.execute_reply.started":"2022-07-22T05:56:07.472942Z","shell.execute_reply":"2022-07-22T05:56:07.678100Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y_pred=model(X_test, W, b)  # 창현님 코딩 참조\n#for i in range(len(y_pred)):\n#print(y_pred[i],Y_test[i])\n\nprint('total accuracy(my_LR) = {:.2%}'.format(float((1-np.abs((y_pred-y_test)/y_test)).mean())))\nprint(W, b)","metadata":{"id":"b5A_DKQl9mae","outputId":"73a83a74-b833-4ae0-8b2b-61ea885efa5a","execution":{"iopub.status.busy":"2022-07-22T05:56:07.684950Z","iopub.execute_input":"2022-07-22T05:56:07.685690Z","iopub.status.idle":"2022-07-22T05:56:07.696229Z","shell.execute_reply.started":"2022-07-22T05:56:07.685641Z","shell.execute_reply":"2022-07-22T05:56:07.694906Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"**회고**\n\n처음에 학습을 진행했을 때는 원하는 값이 나오지 않았습니다. 그래서, learning rate 와 트레이닝 횟수를 계속 조절하였고, loss값을 3000에 근접하도록 얻을 수 있었습니다.","metadata":{}}]}