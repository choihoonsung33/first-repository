{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "멋진 작사가 만들기",
      "provenance": [],
      "collapsed_sections": [
        "5L-NH2i_OeWl",
        "dGfgE3esOsui"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 6-4. 실습 (1) 데이터 다듬기"
      ],
      "metadata": {
        "id": "5L-NH2i_OeWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "# 파일을 읽기모드로 열고\n",
        "# 라인 단위로 끊어서 list 형태로 읽어옵니다.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/aiffel/lyricist/data/shakespeare.txt'\n",
        "with open(file_path, \"r\") as f:\n",
        "    raw_corpus = f.read().splitlines()\n",
        "\n",
        "# 앞에서부터 10라인만 화면에 출력해 볼까요?\n",
        "print(raw_corpus[:9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiDhQB0MOins",
        "outputId": "14182bb6-d496-45ea-d96e-78db6f35e956"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['First Citizen:', 'Before we proceed any further, hear me speak.', '', 'All:', 'Speak, speak.', '', 'First Citizen:', 'You are all resolved rather to die than to famish?', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sentence in enumerate(raw_corpus):\n",
        "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
        "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
        "\n",
        "    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
        "        \n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaww7X47MQb5",
        "outputId": "e26f6a7a-0ba2-42a9-d00a-34525842be5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before we proceed any further, hear me speak.\n",
            "Speak, speak.\n",
            "You are all resolved rather to die than to famish?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력된 문장을\n",
        "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
        "#     2. 특수문자 양쪽에 공백을 넣고\n",
        "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
        "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
        "#     5. 다시 양쪽 공백을 지웁니다\n",
        "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
        "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 1\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
        "    sentence = sentence.strip() # 5\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
        "    return sentence\n",
        "\n",
        "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHe5RYdrNclX",
        "outputId": "2ff585d5-63b1-4ff2-e66d-2d402187db1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 여기에 정제된 문장을 모을겁니다\n",
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    # 정제를 하고 담아주세요\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "# 정제된 결과를 10개만 확인해보죠\n",
        "corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phhqQ-44NmSY",
        "outputId": "cb5c6978-278b-4aab-f68d-cd1e0d63d2b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> before we proceed any further , hear me speak . <end>',\n",
              " '<start> speak , speak . <end>',\n",
              " '<start> you are all resolved rather to die than to famish ? <end>',\n",
              " '<start> resolved . resolved . <end>',\n",
              " '<start> first , you know caius marcius is chief enemy to the people . <end>',\n",
              " '<start> we know t , we know t . <end>',\n",
              " '<start> let us kill him , and we ll have corn at our own price . <end>',\n",
              " '<start> is t a verdict ? <end>',\n",
              " '<start> no more talking on t let it be done away , away ! <end>',\n",
              " '<start> one word , good citizens . <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
        "# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
        "def tokenize(corpus):\n",
        "    # 7000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
        "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
        "    # 7000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=7000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
        "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
        "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY6MGC-0N52O",
        "outputId": "488cf58d-735a-48ad-da6c-6ea6927763cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2  143   40 ...    0    0    0]\n",
            " [   2  110    4 ...    0    0    0]\n",
            " [   2   11   50 ...    0    0    0]\n",
            " ...\n",
            " [   2  149 4553 ...    0    0    0]\n",
            " [   2   34   71 ...    0    0    0]\n",
            " [   2  945   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f3cb587d490>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[:3, :10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQBUUO_OODEO",
        "outputId": "ab7154fc-e4a2-486a-e208-c9c4f5742f11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2  143   40  933  140  591    4  124   24  110]\n",
            " [   2  110    4  110    5    3    0    0    0    0]\n",
            " [   2   11   50   43 1201  316    9  201   74    9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZVu10qdOITv",
        "outputId": "44a46e14-f9e3-431f-e412-ce9374f715ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : .\n",
            "6 : the\n",
            "7 : and\n",
            "8 : i\n",
            "9 : to\n",
            "10 : of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
        "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
        "src_input = tensor[:, :-1]  \n",
        "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIf6ZYGUOL8c",
        "outputId": "e9728cf8-58db-4773-f113-fe64978735e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2 143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0\n",
            "   0   0]\n",
            "[143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0   0\n",
            "   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
        "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
        "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q6s2JCAOPgm",
        "outputId": "0ef00b9a-4cdd-4ff2-fbd8-e78d4caaf6b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 20), dtype=tf.int32, name=None), TensorSpec(shape=(256, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-5. 실습 (2) 인공지능 학습시키기"
      ],
      "metadata": {
        "id": "dGfgE3esOsui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 256\n",
        "hidden_size = 1024\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "2dUld0XyPAsv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
        "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
        "model(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi8d-fanPLfe",
        "outputId": "b220a606-748e-47b9-ac46-5f79e89cf970"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 20, 7001), dtype=float32, numpy=\n",
              "array([[[-2.6919911e-04, -8.9920803e-05, -3.2122916e-04, ...,\n",
              "          1.4933682e-04, -2.1240498e-04, -3.2056746e-04],\n",
              "        [-6.8789127e-04, -6.7614230e-05, -3.5684343e-04, ...,\n",
              "          1.8129857e-04, -3.0017400e-04, -9.7667088e-04],\n",
              "        [-6.8748993e-04, -2.6512414e-04, -2.6814855e-04, ...,\n",
              "          3.7568735e-04, -1.7499921e-04, -1.4515758e-03],\n",
              "        ...,\n",
              "        [ 4.3877866e-03, -4.5274184e-03,  4.0966347e-03, ...,\n",
              "          1.1534910e-03,  3.5059484e-04, -2.8121303e-04],\n",
              "        [ 4.7931825e-03, -4.9261441e-03,  4.4586896e-03, ...,\n",
              "          1.2436017e-03,  5.5538153e-04, -3.5112048e-04],\n",
              "        [ 5.1560397e-03, -5.2775647e-03,  4.7544567e-03, ...,\n",
              "          1.3033461e-03,  7.2581525e-04, -4.1062955e-04]],\n",
              "\n",
              "       [[-2.6919911e-04, -8.9920803e-05, -3.2122916e-04, ...,\n",
              "          1.4933682e-04, -2.1240498e-04, -3.2056746e-04],\n",
              "        [-2.7401742e-04, -3.2437514e-04, -3.2117887e-04, ...,\n",
              "          4.2467276e-04, -3.5257186e-04, -3.5067255e-04],\n",
              "        [-2.0670614e-04, -2.9357127e-04, -3.9565339e-04, ...,\n",
              "          5.9557875e-04, -4.5084377e-04, -4.6182319e-04],\n",
              "        ...,\n",
              "        [ 5.4622227e-03, -4.9961805e-03,  4.2426493e-03, ...,\n",
              "          1.3740369e-03,  9.8208222e-04,  2.5869082e-04],\n",
              "        [ 5.7573877e-03, -5.3527229e-03,  4.5467671e-03, ...,\n",
              "          1.3480764e-03,  1.0688669e-03,  2.2509096e-04],\n",
              "        [ 6.0147769e-03, -5.6564151e-03,  4.7977008e-03, ...,\n",
              "          1.3203420e-03,  1.1430895e-03,  1.7066691e-04]],\n",
              "\n",
              "       [[-2.6919911e-04, -8.9920803e-05, -3.2122916e-04, ...,\n",
              "          1.4933682e-04, -2.1240498e-04, -3.2056746e-04],\n",
              "        [-4.2284257e-04, -1.4150850e-04, -7.7726564e-04, ...,\n",
              "          9.6393145e-05, -2.7494144e-04, -9.4071112e-04],\n",
              "        [ 9.8468468e-07, -6.8118388e-04, -1.1158128e-03, ...,\n",
              "         -2.7199599e-04, -1.9924400e-06, -1.2941945e-03],\n",
              "        ...,\n",
              "        [ 3.7418387e-03, -3.1075545e-03,  3.1945889e-03, ...,\n",
              "          4.0750107e-05,  9.9957548e-04,  1.0453808e-05],\n",
              "        [ 4.1485419e-03, -3.6641243e-03,  3.6147384e-03, ...,\n",
              "          2.0811024e-04,  1.0340241e-03, -2.3794904e-05],\n",
              "        [ 4.5277984e-03, -4.1626119e-03,  3.9756126e-03, ...,\n",
              "          3.5023064e-04,  1.0701775e-03, -8.5099273e-05]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-2.6919911e-04, -8.9920803e-05, -3.2122916e-04, ...,\n",
              "          1.4933682e-04, -2.1240498e-04, -3.2056746e-04],\n",
              "        [ 3.9835475e-05, -2.7872625e-06, -6.8489328e-04, ...,\n",
              "          1.2385243e-04, -1.6514108e-05, -8.7525224e-04],\n",
              "        [ 3.3287963e-04,  2.7784856e-05, -7.4973924e-04, ...,\n",
              "          3.5148911e-04,  3.6831974e-04, -8.0722239e-04],\n",
              "        ...,\n",
              "        [ 5.2599870e-03, -5.0722384e-03,  4.5841276e-03, ...,\n",
              "          1.2385136e-03,  1.1379899e-03, -3.4165379e-04],\n",
              "        [ 5.5758096e-03, -5.4070479e-03,  4.8211971e-03, ...,\n",
              "          1.2390912e-03,  1.1979380e-03, -3.9679042e-04],\n",
              "        [ 5.8563254e-03, -5.6954585e-03,  5.0180727e-03, ...,\n",
              "          1.2356135e-03,  1.2487980e-03, -4.4603916e-04]],\n",
              "\n",
              "       [[-2.6919911e-04, -8.9920803e-05, -3.2122916e-04, ...,\n",
              "          1.4933682e-04, -2.1240498e-04, -3.2056746e-04],\n",
              "        [-8.6478365e-04,  1.7311005e-04, -4.2344039e-04, ...,\n",
              "         -8.5916377e-05, -3.3501076e-04, -2.9291850e-04],\n",
              "        [-8.3813019e-04,  3.8378668e-04, -3.3647215e-04, ...,\n",
              "         -3.9941850e-04, -2.5852738e-05, -1.1456221e-04],\n",
              "        ...,\n",
              "        [ 3.3441419e-03, -3.9285608e-03,  2.1985064e-03, ...,\n",
              "          1.2607757e-03,  1.1492985e-03,  2.8807405e-04],\n",
              "        [ 3.8520899e-03, -4.4278954e-03,  2.7735385e-03, ...,\n",
              "          1.4211717e-03,  1.2301487e-03,  2.7870154e-04],\n",
              "        [ 4.3214913e-03, -4.8719202e-03,  3.2808313e-03, ...,\n",
              "          1.5260534e-03,  1.2990629e-03,  2.3650484e-04]],\n",
              "\n",
              "       [[-2.6919911e-04, -8.9920803e-05, -3.2122916e-04, ...,\n",
              "          1.4933682e-04, -2.1240498e-04, -3.2056746e-04],\n",
              "        [-5.6489016e-04, -3.8656720e-04, -4.5761021e-04, ...,\n",
              "          2.1121121e-04, -5.3367129e-04, -2.9034651e-04],\n",
              "        [-5.6747743e-04, -6.5271452e-04, -6.9323130e-04, ...,\n",
              "          4.1538486e-05, -7.0551032e-04, -2.8999508e-04],\n",
              "        ...,\n",
              "        [ 5.3302217e-03, -4.7853701e-03,  3.8224126e-03, ...,\n",
              "          1.3459977e-03,  7.1602035e-04,  1.1742051e-04],\n",
              "        [ 5.6633838e-03, -5.1608835e-03,  4.1618668e-03, ...,\n",
              "          1.3500453e-03,  8.4447907e-04,  1.3074917e-05],\n",
              "        [ 5.9496192e-03, -5.4877279e-03,  4.4496818e-03, ...,\n",
              "          1.3436200e-03,  9.5083425e-04, -8.0679216e-05]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTDN0La7PMBA",
        "outputId": "ec145b68-fd97-43c1-8e61-d320575398a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  1792256   \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  7176025   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,607,961\n",
            "Trainable params: 22,607,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer와 loss등은 차차 배웁니다 \n",
        "# 혹시 미리 알고 싶다면 아래 문서를 참고하세요\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "# 양이 상당히 많은 편이니 지금 보는 것은 추천하지 않습니다\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "# model.fit() 함수에 들어가는 다양한 인자를 알고 싶다면 아래의 문서를 참고하세요. \n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
        "\n",
        "model.fit(dataset, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "OkN1v8EuPTbX",
        "outputId": "27a306de-dc4a-443c-e387-f1c54017930b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "93/93 [==============================] - 13s 103ms/step - loss: 3.4749\n",
            "Epoch 2/30\n",
            "93/93 [==============================] - 10s 103ms/step - loss: 2.8051\n",
            "Epoch 3/30\n",
            "93/93 [==============================] - 10s 104ms/step - loss: 2.7105\n",
            "Epoch 4/30\n",
            "93/93 [==============================] - 10s 103ms/step - loss: 2.6127\n",
            "Epoch 5/30\n",
            "93/93 [==============================] - 10s 103ms/step - loss: 2.5455\n",
            "Epoch 6/30\n",
            "93/93 [==============================] - 10s 103ms/step - loss: 2.4896\n",
            "Epoch 7/30\n",
            "36/93 [==========>...................] - ETA: 5s - loss: 2.4257"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-732561b014a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-7. 프로젝트: 멋진 작사가 만들기"
      ],
      "metadata": {
        "id": "XAIzTU4hRsXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os, re \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "# 파일을 읽기모드로 열고\n",
        "# 라인 단위로 끊어서 list 형태로 읽어옵니다.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/aiffel/lyricist/data/lyrics/*'\n",
        "txt_list = glob.glob(file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgcmXASeSkKI",
        "outputId": "fb1253ed-7623-4f92-fac1-2fd048bfd4bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "데이터 크기: 187088\n",
            "Examples:\n",
            " [\"Let's stay together I, I'm I'm so in love with you\", 'Whatever you want to do', 'Is all right with me']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sentence in enumerate(raw_corpus):\n",
        "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
        "\n",
        "    if idx > 9: break   # 문장 10개 확인\n",
        "        \n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaxedLskf7Zp",
        "outputId": "af205268-5444-4e45-f9f6-08dbb87c058e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's stay together I, I'm I'm so in love with you\n",
            "Whatever you want to do\n",
            "Is all right with me\n",
            "Cause you make me feel so brand new\n",
            "And I want to spend my life with you Let me say that since, baby, since we've been together\n",
            "Loving you forever\n",
            "Is what I need\n",
            "Let me, be the one you come running to\n",
            "I'll never be untrue Oh baby\n",
            "Let's, let's stay together (gether)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰화\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 특수문자 양쪽에 공백을 넣고\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개의 공백은 하나의 공백으로 바꿉니다\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
        "    sentence = sentence.strip() # 다시 양쪽 공백을 지웁니다\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "nRRolig3f7-t"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#정제 데이터 구축하기\n",
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    if len(sentence) == 0: continue #길이 0\n",
        "    if len(sentence.split()) >= 13: continue  #15개 이하(start,end포함)\n",
        "    \n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "    \n",
        "    \n",
        "corpus[:10] #정제결과 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7QSnwKWgA3L",
        "outputId": "8e12c5e4-ab61-4154-90bd-bb301d8184f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> let s stay together i , i m i m so in love with you <end>',\n",
              " '<start> whatever you want to do <end>',\n",
              " '<start> is all right with me <end>',\n",
              " '<start> cause you make me feel so brand new <end>',\n",
              " '<start> loving you forever <end>',\n",
              " '<start> is what i need <end>',\n",
              " '<start> let me , be the one you come running to <end>',\n",
              " '<start> i ll never be untrue oh baby <end>',\n",
              " '<start> let s , let s stay together gether <end>',\n",
              " '<start> lovin you whether , whether <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize() 함수로 데이터를 Tensor로 변환\n",
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000, #단어장의 크기:12,000 이상 \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    \n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)  # corpus를 Tensor로 변환 \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qc6-5qqgNP1",
        "outputId": "2e71668a-28ef-4eb9-f9ea-30b82227c262"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2  64  16 ...   0   0   0]\n",
            " [  2 576   7 ...   0   0   0]\n",
            " [  2  26  25 ...   0   0   0]\n",
            " ...\n",
            " [  2  42 904 ...   0   0   0]\n",
            " [  2  42  67 ...   0   0   0]\n",
            " [  2   8  83 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f3c364b9690>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어사전 구축 인덱스 확인\n",
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break\n",
        "\n",
        "#생성된 텐서를 소스와 타겟으로 분리해 모델 학습\n",
        "src_input = tensor[:, :-1]   #소스 문장을 생성\n",
        "tgt_input = tensor[:, 1:]   #타겟 문장을 생성\n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZKCsj_egRkc",
        "outputId": "81035067-af46-4923-9120-6328170213d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n",
            "[  2  64  16 215 277   5   4   5  23   5  23  31  14  37  30   7   3   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "[ 64  16 215 277   5   4   5  23   5  23  31  14  37  30   7   3   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 객체 생성\n",
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MScmfWcwgV9O",
        "outputId": "5b2f74f8-8c79-4e53-95de-e182e17475f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 32), dtype=tf.int32, name=None), TensorSpec(shape=(256, 32), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#총 데이터의 20% 를 평가 데이터셋\n",
        "from sklearn.model_selection import train_test_split\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2)"
      ],
      "metadata": {
        "id": "qK9DG4EKgY8z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 256  # 워드 벡터의 차원수, 즉 단어가 추상적으로 표현되는 크기\n",
        "hidden_size = 1024  #모델에 얼마나 많은 일꾼을 둘 것인가\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "3y9OcfRNgcxL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러오기\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUinAEf2hKCI",
        "outputId": "650f5e25-b380-42d0-b303-7f523a8a2680"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 32, 12001), dtype=float32, numpy=\n",
              "array([[[ 9.71938061e-05,  3.74648953e-05,  2.24315245e-05, ...,\n",
              "          4.74630406e-06,  2.05467528e-04, -8.49013231e-05],\n",
              "        [-5.09941710e-05, -4.10352572e-04,  3.31989460e-04, ...,\n",
              "         -2.10079481e-04,  3.22111562e-04, -2.45584524e-04],\n",
              "        [-7.82156421e-05, -5.79811342e-04,  1.74080080e-04, ...,\n",
              "         -3.48990317e-04,  2.53129256e-04, -1.12846523e-04],\n",
              "        ...,\n",
              "        [ 8.03558563e-04, -1.91127567e-03, -3.11646843e-03, ...,\n",
              "          1.36775512e-03, -4.29297244e-04,  3.44349479e-04],\n",
              "        [ 7.92811334e-04, -1.90515327e-03, -3.13675893e-03, ...,\n",
              "          1.37712224e-03, -4.52137640e-04,  3.36127472e-04],\n",
              "        [ 7.83081574e-04, -1.90035382e-03, -3.15507548e-03, ...,\n",
              "          1.38541777e-03, -4.71753738e-04,  3.29465605e-04]],\n",
              "\n",
              "       [[ 9.71938061e-05,  3.74648953e-05,  2.24315245e-05, ...,\n",
              "          4.74630406e-06,  2.05467528e-04, -8.49013231e-05],\n",
              "        [ 3.14505334e-04, -3.52564894e-05,  1.29875029e-04, ...,\n",
              "          1.38295174e-04,  9.50281683e-05,  1.29290740e-04],\n",
              "        [ 4.01645928e-04, -2.58493208e-04,  1.92672189e-04, ...,\n",
              "          1.73338602e-04, -9.57686862e-05,  6.16594858e-04],\n",
              "        ...,\n",
              "        [ 7.61787989e-04, -1.97892915e-03, -3.25022452e-03, ...,\n",
              "          1.44517841e-03, -4.05353931e-04,  3.43065476e-04],\n",
              "        [ 7.55429966e-04, -1.97016145e-03, -3.25332815e-03, ...,\n",
              "          1.44224416e-03, -4.32616129e-04,  3.37408128e-04],\n",
              "        [ 7.49530445e-04, -1.96197350e-03, -3.25648766e-03, ...,\n",
              "          1.44028675e-03, -4.55840083e-04,  3.32796335e-04]],\n",
              "\n",
              "       [[ 9.71938061e-05,  3.74648953e-05,  2.24315245e-05, ...,\n",
              "          4.74630406e-06,  2.05467528e-04, -8.49013231e-05],\n",
              "        [ 1.18194796e-04, -6.96404531e-05, -2.45790317e-04, ...,\n",
              "          1.87449332e-04,  4.07574582e-04, -2.56344560e-04],\n",
              "        [ 2.13652849e-04, -1.09816592e-05, -1.57445160e-04, ...,\n",
              "          1.32317102e-04,  5.19094523e-04, -6.00595667e-04],\n",
              "        ...,\n",
              "        [ 7.75499095e-04, -1.94814953e-03, -3.18237441e-03, ...,\n",
              "          1.39814895e-03, -4.01000842e-04,  3.17253231e-04],\n",
              "        [ 7.68670230e-04, -1.94064213e-03, -3.19368672e-03, ...,\n",
              "          1.40636682e-03, -4.28624160e-04,  3.14552221e-04],\n",
              "        [ 7.62214069e-04, -1.93407235e-03, -3.20433057e-03, ...,\n",
              "          1.41326035e-03, -4.52401699e-04,  3.12418881e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 9.71938061e-05,  3.74648953e-05,  2.24315245e-05, ...,\n",
              "          4.74630406e-06,  2.05467528e-04, -8.49013231e-05],\n",
              "        [ 9.70322162e-06,  1.44969948e-04,  1.58799419e-04, ...,\n",
              "          3.24791072e-05,  3.19523155e-04, -2.86839437e-04],\n",
              "        [-1.48751162e-04,  1.77177571e-05,  2.12386803e-05, ...,\n",
              "         -2.24548639e-04,  5.14958578e-04, -2.93343066e-04],\n",
              "        ...,\n",
              "        [ 7.69714301e-04, -1.93186221e-03, -3.22158262e-03, ...,\n",
              "          1.46598148e-03, -4.74459492e-04,  2.33245111e-04],\n",
              "        [ 7.58481154e-04, -1.92808989e-03, -3.22801690e-03, ...,\n",
              "          1.46443420e-03, -4.94128559e-04,  2.45036790e-04],\n",
              "        [ 7.48939812e-04, -1.92467228e-03, -3.23424395e-03, ...,\n",
              "          1.46270380e-03, -5.10416168e-04,  2.55149032e-04]],\n",
              "\n",
              "       [[ 9.71938061e-05,  3.74648953e-05,  2.24315245e-05, ...,\n",
              "          4.74630406e-06,  2.05467528e-04, -8.49013231e-05],\n",
              "        [ 6.91303067e-05,  5.13489140e-05,  1.03735336e-04, ...,\n",
              "          6.69646834e-05,  5.38261433e-04, -2.27655692e-04],\n",
              "        [ 7.48450911e-05,  1.34329748e-04, -3.89293564e-05, ...,\n",
              "          2.54765706e-04,  7.22841243e-04, -2.46778392e-04],\n",
              "        ...,\n",
              "        [ 8.13674298e-04, -1.94839912e-03, -3.13564320e-03, ...,\n",
              "          1.39750855e-03, -1.39586686e-04,  2.59594904e-04],\n",
              "        [ 8.00253183e-04, -1.94707967e-03, -3.14951059e-03, ...,\n",
              "          1.40451023e-03, -2.03726493e-04,  2.61822861e-04],\n",
              "        [ 7.87163386e-04, -1.94457802e-03, -3.16229835e-03, ...,\n",
              "          1.41063903e-03, -2.59979774e-04,  2.64488655e-04]],\n",
              "\n",
              "       [[ 9.71938061e-05,  3.74648953e-05,  2.24315245e-05, ...,\n",
              "          4.74630406e-06,  2.05467528e-04, -8.49013231e-05],\n",
              "        [ 1.95498782e-04, -1.49938220e-04,  3.85987187e-05, ...,\n",
              "          2.72410671e-06,  2.02747033e-04,  2.29255718e-04],\n",
              "        [ 2.23002062e-05, -2.52408441e-04,  2.05691904e-04, ...,\n",
              "         -1.06712505e-05,  1.33198773e-04,  6.14689896e-04],\n",
              "        ...,\n",
              "        [ 7.43944955e-04, -1.90273358e-03, -3.22667020e-03, ...,\n",
              "          1.45938282e-03, -4.30804590e-04,  3.35810473e-04],\n",
              "        [ 7.37767085e-04, -1.90323114e-03, -3.23395175e-03, ...,\n",
              "          1.45814533e-03, -4.56092530e-04,  3.31523828e-04],\n",
              "        [ 7.32381421e-04, -1.90354278e-03, -3.24064633e-03, ...,\n",
              "          1.45685673e-03, -4.77476890e-04,  3.28089605e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg0ekKqXhNG3",
        "outputId": "138a5413-5228-4796-bf6e-270284fada91"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     multiple                  3072256   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  12301025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,012,961\n",
            "Trainable params: 29,012,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습하기\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUxLMerJhT4C",
        "outputId": "f71fc12b-67c3-4b64-bef2-2efe0cf23906"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "620/620 [==============================] - 123s 195ms/step - loss: 1.5989\n",
            "Epoch 2/10\n",
            "620/620 [==============================] - 121s 195ms/step - loss: 1.3317\n",
            "Epoch 3/10\n",
            "620/620 [==============================] - 121s 195ms/step - loss: 1.2617\n",
            "Epoch 4/10\n",
            "620/620 [==============================] - 121s 195ms/step - loss: 1.1984\n",
            "Epoch 5/10\n",
            "620/620 [==============================] - 121s 195ms/step - loss: 1.1480\n",
            "Epoch 6/10\n",
            "620/620 [==============================] - 121s 195ms/step - loss: 1.1028\n",
            "Epoch 7/10\n",
            "620/620 [==============================] - 121s 195ms/step - loss: 1.0609\n",
            "Epoch 8/10\n",
            "620/620 [==============================] - 121s 195ms/step - loss: 1.0221\n",
            "Epoch 9/10\n",
            "620/620 [==============================] - 121s 195ms/step - loss: 0.9852\n",
            "Epoch 10/10\n",
            "620/620 [==============================] - 121s 195ms/step - loss: 0.9505\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3bd90d7b50>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    # 단어 하나씩 예측해 문장을 만듭니다\n",
        "    while True:\n",
        "        # 입력받은 문장의 텐서를 입력\n",
        "        predict = model(test_tensor) \n",
        "        # 예측된 값 중 가장 높은 확률인 word index를 뽑기\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 예측된 word index를 문장 뒤에 붙임\n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마침\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "GAITyoM2hXnB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#문장 생성 함수 실행\n",
        "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "APJCIZwEHCwf",
        "outputId": "c6535d18-9130-4599-d67e-f53a01312f04"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love you , baby <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x10pcGQUHLt9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}